{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary libraries\n",
    "# !pip install cdsapi xarray matplotlib netCDF4\n",
    "\n",
    "import cdsapi\n",
    "from pathlib import Path\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ERA5 data from 1940 to 2024...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-08 00:29:15,215 INFO Request ID is 3ae183b4-0243-4f90-a7e1-4baca8c21a19\n",
      "2024-09-08 00:29:15,421 INFO status has been updated to accepted\n",
      "2024-09-08 00:29:17,234 INFO status has been updated to failed\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "400 Client Error: Bad Request for url: https://cds-beta.climate.copernicus.eu/api/retrieve/v1/jobs/3ae183b4-0243-4f90-a7e1-4baca8c21a19/results\nThe job has failed.\nThe job failed with: ValueError",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19056\\1133479544.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0moutput_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Downloading ERA5 data from {0} to {1}...\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_year\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_year\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     c.retrieve(\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[1;34m'reanalysis-era5-pressure-levels-monthly-means'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         {\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\cads_api_client\\legacy_api_client.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self, name, request, target)\u001b[0m\n\u001b[0;32m    151\u001b[0m         \u001b[0msubmitted\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRemote\u001b[0m \u001b[1;33m|\u001b[0m \u001b[0mprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mResults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait_until_complete\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m             submitted = self.logging_decorator(self.client.submit_and_wait_on_result)(\n\u001b[0m\u001b[0;32m    154\u001b[0m                 \u001b[0mcollection_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m                 \u001b[0mretry_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretry_options\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\cads_api_client\\legacy_api_client.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquiet\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquiet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_debug\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m             ):\n\u001b[1;32m--> 136\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\cads_api_client\\api_client.py\u001b[0m in \u001b[0;36msubmit_and_wait_on_result\u001b[1;34m(self, collection_id, retry_options, **request)\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollection_id\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretry_options\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m     ) -> processing.Results:\n\u001b[1;32m---> 78\u001b[1;33m         return self.retrieve_api.submit_and_wait_on_result(\n\u001b[0m\u001b[0;32m     79\u001b[0m             \u001b[0mcollection_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretry_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mretry_options\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m         )\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\cads_api_client\\processing.py\u001b[0m in \u001b[0;36msubmit_and_wait_on_result\u001b[1;34m(self, collection_id, retry_options, **request)\u001b[0m\n\u001b[0;32m    535\u001b[0m     ) -> Results:\n\u001b[0;32m    536\u001b[0m         \u001b[0mremote\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcollection_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretry_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mretry_options\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 537\u001b[1;33m         \u001b[0mremote\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait_on_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mretry_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mretry_options\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    538\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mremote\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_results\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\cads_api_client\\processing.py\u001b[0m in \u001b[0;36mwait_on_result\u001b[1;34m(self, retry_options)\u001b[0m\n\u001b[0;32m    238\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"failed\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 240\u001b[1;33m                 \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmultiurl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrobust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_results\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mretry_options\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    241\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mProcessingFailedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_json_to_message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"accepted\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"running\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\multiurl\\http.py\u001b[0m in \u001b[0;36mwrapped\u001b[1;34m(url, *args, **kwargs)\u001b[0m\n\u001b[0;32m    469\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    470\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 471\u001b[1;33m                 \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    472\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSSLError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    473\u001b[0m                 \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\cads_api_client\\processing.py\u001b[0m in \u001b[0;36mmake_results\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m    269\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m             \u001b[0mresults_url\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"{url}/results\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 271\u001b[1;33m         results = Results.from_request(\n\u001b[0m\u001b[0;32m    272\u001b[0m             \u001b[1;34m\"get\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m             \u001b[0mresults_url\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\cads_api_client\\processing.py\u001b[0m in \u001b[0;36mfrom_request\u001b[1;34m(cls, raise_for_status, session, retry_options, *args, **kwargs)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mraise_for_status\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m             \u001b[0mcads_raise_for_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m         \u001b[0mself\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"headers\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_messages\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\cads_api_client\\processing.py\u001b[0m in \u001b[0;36mcads_raise_for_status\u001b[1;34m(response)\u001b[0m\n\u001b[0;32m     53\u001b[0m                 ]\n\u001b[0;32m     54\u001b[0m             )\n\u001b[1;32m---> 55\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHTTPError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m     \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mHTTPError\u001b[0m: 400 Client Error: Bad Request for url: https://cds-beta.climate.copernicus.eu/api/retrieve/v1/jobs/3ae183b4-0243-4f90-a7e1-4baca8c21a19/results\nThe job has failed.\nThe job failed with: ValueError"
     ]
    }
   ],
   "source": [
    "# Initialize the CDS API client\n",
    "c = cdsapi.Client()\n",
    "\n",
    "# Define the Alberta bounding box (North, West, South, East)\n",
    "# bbox = [60, -120, 50, -110]  # Alberta, Canada\n",
    "bbox = [83, -170, 24, -50]  # North America\n",
    "pressure_levels = ['250', '500', '850', '1000'] \n",
    "start_year = 1940\n",
    "end_year = 2023\n",
    "\n",
    "# Path to save the downloaded NetCDF file\n",
    "dir = Path(r'D:\\UCalgary_Lectures\\GEOG_683\\Data_workspace')\n",
    "output_file = dir / 'NAmerica_geopotential_1940_2023.nc'\n",
    "\n",
    "# Step 1: Download the data using the CDS API\n",
    "if not output_file.exists():\n",
    "    print(\"Downloading ERA5 data from {0} to {1}...\".format(start_year, end_year))\n",
    "    c.retrieve(\n",
    "        'reanalysis-era5-pressure-levels-monthly-means',\n",
    "        {\n",
    "            'product_type': 'reanalysis',\n",
    "            'format': 'netcdf',\n",
    "            'variable': ['u_component_of_wind', 'v_component_of_wind', 'geopotential', 'temperature'],  \n",
    "            'pressure_level': pressure_levels,\n",
    "            'year': [str(year) for year in range(start_year, end_year+1)],\n",
    "            'month': [f'{month:02d}' for month in range(1, 13)],\n",
    "            'time': ['12:00'],\n",
    "            'area': bbox,\n",
    "        },\n",
    "        str(output_file)\n",
    "    )\n",
    "    print(\"Download complete.\")\n",
    "else:\n",
    "    print(f\"File {output_file} already exists. Skipping download.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:         (date: 1008, pressure_level: 4, latitude: 237,\n",
      "                     longitude: 481)\n",
      "Coordinates:\n",
      "  * date            (date) int64 19400101 19400201 ... 20231101 20231201\n",
      "  * pressure_level  (pressure_level) float64 1e+03 850.0 500.0 250.0\n",
      "  * latitude        (latitude) float64 83.0 82.75 82.5 82.25 ... 24.5 24.25 24.0\n",
      "  * longitude       (longitude) float64 -170.0 -169.8 -169.5 ... -50.25 -50.0\n",
      "Data variables:\n",
      "    number          int64 ...\n",
      "    expver          (date) object ...\n",
      "    u               (date, pressure_level, latitude, longitude) float32 ...\n",
      "    v               (date, pressure_level, latitude, longitude) float32 ...\n",
      "    z               (date, pressure_level, latitude, longitude) float32 ...\n",
      "    t               (date, pressure_level, latitude, longitude) float32 ...\n",
      "Attributes:\n",
      "    GRIB_centre:             ecmf\n",
      "    GRIB_centreDescription:  European Centre for Medium-Range Weather Forecasts\n",
      "    GRIB_subCentre:          0\n",
      "    Conventions:             CF-1.7\n",
      "    institution:             European Centre for Medium-Range Weather Forecasts\n",
      "    history:                 2024-09-08T06:53 GRIB to CDM+CF via cfgrib-0.9.1...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "# Load the netCDF file\n",
    "ds_2 = xr.open_dataset(r'D:\\UCalgary_Lectures\\GEOG_683\\Data_workspace\\NAmerica_geopotential_1940_2023.nc')\n",
    "\n",
    "print(ds_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray 'date' (date: 1008)>\n",
      "array([19400101, 19400201, 19400301, ..., 20231001, 20231101, 20231201],\n",
      "      dtype=int64)\n",
      "Coordinates:\n",
      "  * date     (date) int64 19400101 19400201 19400301 ... 20231101 20231201\n",
      "Attributes:\n",
      "    long_name:  original GRIB coordinate for key: date(date)\n",
      "    units:      1\n"
     ]
    }
   ],
   "source": [
    "print(ds_2['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert Date to Datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'ds' is your xarray dataset and 'date' is the array of integers\n",
    "date_array = ds_2['date'].values\n",
    "\n",
    "# Convert the array to datetime using pandas\n",
    "dates_as_datetime = pd.to_datetime(date_array.astype(str), format='%Y%m%d')\n",
    "\n",
    "# Add the new datetime array to the dataset as a new variable\n",
    "ds_2 = ds_2.assign(datetime=('date', dates_as_datetime))\n",
    "\n",
    "# Print the dataset to verify the new 'datetime' variable\n",
    "ds_2.to_netcdf(r'D:\\UCalgary_Lectures\\GEOG_683\\Data_workspace\\NAmerica_geopotential_1940_2023_2.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:         (pressure_level: 4, latitude: 237, longitude: 481,\n",
      "                     date: 1008)\n",
      "Coordinates:\n",
      "  * pressure_level  (pressure_level) float64 1e+03 850.0 500.0 250.0\n",
      "  * latitude        (latitude) float64 83.0 82.75 82.5 82.25 ... 24.5 24.25 24.0\n",
      "  * longitude       (longitude) float64 -170.0 -169.8 -169.5 ... -50.25 -50.0\n",
      "  * date            (date) datetime64[ns] 1940-01-01 1940-02-01 ... 2023-12-01\n",
      "Data variables:\n",
      "    number          int64 ...\n",
      "    expver          (date) object ...\n",
      "    u               (date, pressure_level, latitude, longitude) float32 ...\n",
      "    v               (date, pressure_level, latitude, longitude) float32 ...\n",
      "    z               (date, pressure_level, latitude, longitude) float32 ...\n",
      "    t               (date, pressure_level, latitude, longitude) float32 ...\n",
      "Attributes:\n",
      "    GRIB_centre:             ecmf\n",
      "    GRIB_centreDescription:  European Centre for Medium-Range Weather Forecasts\n",
      "    GRIB_subCentre:          0\n",
      "    Conventions:             CF-1.7\n",
      "    institution:             European Centre for Medium-Range Weather Forecasts\n",
      "    history:                 2024-09-08T06:53 GRIB to CDM+CF via cfgrib-0.9.1...\n"
     ]
    }
   ],
   "source": [
    "ds_2 = xr.open_dataset(r'D:\\UCalgary_Lectures\\GEOG_683\\Data_workspace\\NAmerica_geopotential_1940_2023_2.nc')\n",
    "print(ds_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray 'datetime' (date: 1008)>\n",
      "[1008 values with dtype=datetime64[ns]]\n",
      "Coordinates:\n",
      "  * date     (date) int64 19400101 19400201 19400301 ... 20231101 20231201\n"
     ]
    }
   ],
   "source": [
    "print(ds_2['datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray 'date' (date: 1008)>\n",
      "array(['1940-01-01T00:00:00.000000000', '1940-02-01T00:00:00.000000000',\n",
      "       '1940-03-01T00:00:00.000000000', ..., '2023-10-01T00:00:00.000000000',\n",
      "       '2023-11-01T00:00:00.000000000', '2023-12-01T00:00:00.000000000'],\n",
      "      dtype='datetime64[ns]')\n",
      "Coordinates:\n",
      "  * date     (date) datetime64[ns] 1940-01-01 1940-02-01 ... 2023-12-01\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'ds' is your xarray dataset and 'date' is the array of integers\n",
    "date_array = ds_2['date'].values\n",
    "\n",
    "# Convert the array to datetime using pandas\n",
    "dates_as_datetime = pd.to_datetime(date_array.astype(str), format='%Y%m%d')\n",
    "\n",
    "# Remove the old 'date' variable and replace it with the datetime values\n",
    "ds_2 = ds_2.drop_vars('date')  # Remove the original 'date' variable\n",
    "ds_2 = ds_2.assign_coords(date=dates_as_datetime)  # Assign the new datetime array as 'date'\n",
    "\n",
    "# Check if the replacement worked\n",
    "print(ds_2['date'])\n",
    "\n",
    "# Save the updated dataset to a new NetCDF file\n",
    "ds_2.to_netcdf(r'D:\\UCalgary_Lectures\\GEOG_683\\Data_workspace\\NAmerica_geopotential_1940_2023_2.nc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1008, 237, 481)\n",
      "<xarray.DataArray 't' (date: 1008, latitude: 237, longitude: 481)>\n",
      "array([[[-61.748764, -61.737045, -61.729233, ..., -55.72728 ,\n",
      "         -55.73607 , -55.74681 ],\n",
      "        [-61.603256, -61.604233, -61.60814 , ..., -55.203842,\n",
      "         -55.21556 , -55.229233],\n",
      "        [-61.51146 , -61.521225, -61.53392 , ..., -54.655014,\n",
      "         -54.66771 , -54.683334],\n",
      "        ...,\n",
      "        [-42.964584, -42.95677 , -42.967514, ..., -43.56517 ,\n",
      "         -43.58568 , -43.617905],\n",
      "        [-42.95482 , -42.939194, -42.938217, ..., -43.239   ,\n",
      "         -43.274155, -43.313217],\n",
      "        [-42.987045, -42.96849 , -42.9597  , ..., -42.95482 ,\n",
      "         -42.994858, -43.034897]],\n",
      "\n",
      "       [[-55.111816, -55.11963 , -55.128418, ..., -52.458496,\n",
      "         -52.48877 , -52.52002 ],\n",
      "        [-55.220215, -55.228027, -55.23584 , ..., -52.467285,\n",
      "         -52.50049 , -52.535645],\n",
      "        [-55.31201 , -55.319824, -55.328613, ..., -52.458496,\n",
      "         -52.492676, -52.527832],\n",
      "...\n",
      "        [-41.979095, -42.039642, -42.092377, ..., -41.17148 ,\n",
      "         -41.10605 , -41.072845],\n",
      "        [-41.934174, -41.96933 , -41.99472 , ..., -41.23398 ,\n",
      "         -41.184174, -41.157806],\n",
      "        [-41.81308 , -41.8248  , -41.831635, ..., -41.299408,\n",
      "         -41.26718 , -41.25058 ]],\n",
      "\n",
      "       [[-59.631958, -59.62024 , -59.608032, ..., -60.58264 ,\n",
      "         -60.584106, -60.585083],\n",
      "        [-59.630493, -59.620728, -59.610962, ..., -60.53772 ,\n",
      "         -60.541138, -60.544556],\n",
      "        [-59.586548, -59.579712, -59.572876, ..., -60.505493,\n",
      "         -60.509888, -60.514282],\n",
      "        ...,\n",
      "        [-44.353638, -44.266235, -44.117798, ..., -48.712036,\n",
      "         -48.839478, -48.85608 ],\n",
      "        [-44.163696, -44.070435, -43.917114, ..., -48.66858 ,\n",
      "         -48.71692 , -48.66028 ],\n",
      "        [-43.970337, -43.882935, -43.738403, ..., -48.497192,\n",
      "         -48.45569 , -48.334595]]], dtype=float32)\n",
      "Coordinates:\n",
      "    pressure_level  float64 250.0\n",
      "  * latitude        (latitude) float64 83.0 82.75 82.5 82.25 ... 24.5 24.25 24.0\n",
      "  * longitude       (longitude) float64 -170.0 -169.8 -169.5 ... -50.25 -50.0\n",
      "  * date            (date) datetime64[ns] 1940-01-01 1940-02-01 ... 2023-12-01\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "from scipy.stats import theilslopes\n",
    "import rasterio\n",
    "from rasterio.transform import from_origin\n",
    "\n",
    "# Step 1: Open the ERA5 netCDF file and extract 1000mb temperature data\n",
    "nc_file = r'D:\\UCalgary_Lectures\\GEOG_683\\Data_workspace\\NAmerica_geopotential_1940_2023_2.nc'\n",
    "ds_2 = xr.open_dataset(nc_file)\n",
    "\n",
    "# Step 2: Extract the temperature ('t') variable at the 1000mb pressure level\n",
    "t_1000mb = ds_2['t'].sel(pressure_level=250)  # Extract temperature at 1000mb\n",
    "\n",
    "# Step 3: Convert the temperature from Kelvin to Celsius\n",
    "t_1000mb_celsius = t_1000mb - 273.15  # Convert to Celsius\n",
    "\n",
    "# Step 4: Extract the time and temperature data (in Celsius now)\n",
    "time = np.arange(len(ds_2['date']))  # Use the indices of the 'date' variable as time\n",
    "temperature_data = t_1000mb_celsius.values  # 4D array (date, latitude, longitude)\n",
    "\n",
    "# Step 5: Prepare the latitude and longitude coordinates\n",
    "lat = ds_2['latitude'].values\n",
    "lon = ds_2['longitude'].values\n",
    "\n",
    "print(t_1000mb.shape)\n",
    "print(t_1000mb_celsius)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeoTIFF saved as D:\\UCalgary_Lectures\\GEOG_683\\Data_workspace\\theil_sen_slope_1000mb_temperature.tif\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Prepare an array to store the Theil-Sen slopes\n",
    "slope_array = np.zeros((len(lat), len(lon)), dtype=np.float32)\n",
    "\n",
    "# Step 6: Perform Theil-Sen regression for each pixel (latitude, longitude)\n",
    "for i in range(len(lat)):\n",
    "    for j in range(len(lon)):\n",
    "        # Extract the temperature time series for the current pixel\n",
    "        pixel_time_series = temperature_data[:, i, j]\n",
    "        \n",
    "        # Check if the pixel contains any NaN values (skip if invalid data)\n",
    "        if np.any(np.isnan(pixel_time_series)):\n",
    "            slope_array[i, j] = np.nan  # Set slope to NaN for invalid data\n",
    "        else:\n",
    "            # Apply Theil-Sen regression\n",
    "            slope, _, _, _ = theilslopes(pixel_time_series, time)\n",
    "            slope_array[i, j] = slope  # Store the slope in the slope array\n",
    "\n",
    "# Step 7: Define the affine transform for the GeoTIFF\n",
    "transform = from_origin(np.min(lon), np.max(lat), np.abs(lon[1] - lon[0]), np.abs(lat[1] - lat[0]))\n",
    "\n",
    "# Step 8: Define the metadata for the GeoTIFF\n",
    "meta = {\n",
    "    'driver': 'GTiff',\n",
    "    'height': slope_array.shape[0],\n",
    "    'width': slope_array.shape[1],\n",
    "    'count': 1,  # Single band (slope)\n",
    "    'dtype': 'float32',\n",
    "    'crs': 'EPSG:4326',  # Assuming WGS84 (adjust if necessary)\n",
    "    'transform': transform\n",
    "}\n",
    "\n",
    "# Step 9: Save the slope result as a GeoTIFF\n",
    "output_tif = r'D:\\UCalgary_Lectures\\GEOG_683\\Data_workspace\\theil_sen_slope_250mb_temperature.tif'\n",
    "with rasterio.open(output_tif, 'w', **meta) as dst:\n",
    "    dst.write(slope_array, 1)  # Write the slope array to band 1\n",
    "\n",
    "print(f\"GeoTIFF saved as {output_tif}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate yearly mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yearly averaged netCDF file saved as D:\\UCalgary_Lectures\\GEOG_683\\Data_workspace\\NAmerica_geopotential_1940_2023_2_yearly.nc\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "\n",
    "# Step 1: Open the original ERA5 netCDF file\n",
    "nc_file = r'D:\\UCalgary_Lectures\\GEOG_683\\Data_workspace\\NAmerica_geopotential_1940_2023_2.nc'\n",
    "ds_2 = xr.open_dataset(nc_file)\n",
    "\n",
    "# Step 2: Resample the dataset to yearly means for each variable and pressure level\n",
    "# This will calculate the yearly mean for each variable (t, u, v, z) at each pressure level\n",
    "ds_yearly_avg = ds_2.resample(date='Y').mean()\n",
    "\n",
    "# Step 3: Save the yearly averaged data to a new netCDF file\n",
    "output_nc_file = r'D:\\UCalgary_Lectures\\GEOG_683\\Data_workspace\\NAmerica_geopotential_1940_2023_2_yearly.nc'\n",
    "ds_yearly_avg.to_netcdf(output_nc_file)\n",
    "\n",
    "print(f\"Yearly averaged netCDF file saved as {output_nc_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:         (date: 84, pressure_level: 4, latitude: 237, longitude: 481)\n",
      "Coordinates:\n",
      "  * pressure_level  (pressure_level) float64 1e+03 850.0 500.0 250.0\n",
      "  * latitude        (latitude) float64 83.0 82.75 82.5 82.25 ... 24.5 24.25 24.0\n",
      "  * longitude       (longitude) float64 -170.0 -169.8 -169.5 ... -50.25 -50.0\n",
      "  * date            (date) datetime64[ns] 1940-12-31 1941-12-31 ... 2023-12-31\n",
      "Data variables:\n",
      "    number          (date) float64 ...\n",
      "    u               (date, pressure_level, latitude, longitude) float32 ...\n",
      "    v               (date, pressure_level, latitude, longitude) float32 ...\n",
      "    z               (date, pressure_level, latitude, longitude) float32 ...\n",
      "    t               (date, pressure_level, latitude, longitude) float32 ...\n",
      "Attributes:\n",
      "    GRIB_centre:             ecmf\n",
      "    GRIB_centreDescription:  European Centre for Medium-Range Weather Forecasts\n",
      "    GRIB_subCentre:          0\n",
      "    Conventions:             CF-1.7\n",
      "    institution:             European Centre for Medium-Range Weather Forecasts\n",
      "    history:                 2024-09-08T06:53 GRIB to CDM+CF via cfgrib-0.9.1...\n"
     ]
    }
   ],
   "source": [
    "nc_file = r'D:\\UCalgary_Lectures\\GEOG_683\\Data_workspace\\NAmerica_geopotential_1940_2023_2_yearly.nc'\n",
    "ds_2 = xr.open_dataset(nc_file)\n",
    "print(ds_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(84, 237, 481)\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Extract the temperature ('t') variable at the 1000mb pressure level\n",
    "t_1000mb = ds_2['t'].sel(pressure_level=1000)  # Extract temperature at 1000mb\n",
    "\n",
    "# Step 3: Convert the temperature from Kelvin to Celsius\n",
    "t_1000mb_celsius = t_1000mb - 273.15  # Convert to Celsius\n",
    "\n",
    "# Step 4: Extract the time and temperature data (in Celsius now)\n",
    "time = np.arange(len(ds_2['date']))  # Use the indices of the 'date' variable as time\n",
    "temperature_data = t_1000mb_celsius.values  # 4D array (date, latitude, longitude)\n",
    "\n",
    "# Step 5: Prepare the latitude and longitude coordinates\n",
    "lat = ds_2['latitude'].values\n",
    "lon = ds_2['longitude'].values\n",
    "\n",
    "print(t_1000mb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeoTIFF saved as D:\\UCalgary_Lectures\\GEOG_683\\Data_workspace\\theil_sen_slope_1000mb_temp_yearly.tif\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Prepare an array to store the Theil-Sen slopes\n",
    "slope_array = np.zeros((len(lat), len(lon)), dtype=np.float32)\n",
    "\n",
    "# Step 6: Perform Theil-Sen regression for each pixel (latitude, longitude)\n",
    "for i in range(len(lat)):\n",
    "    for j in range(len(lon)):\n",
    "        # Extract the temperature time series for the current pixel\n",
    "        pixel_time_series = temperature_data[:, i, j]\n",
    "        \n",
    "        # Check if the pixel contains any NaN values (skip if invalid data)\n",
    "        if np.any(np.isnan(pixel_time_series)):\n",
    "            slope_array[i, j] = np.nan  # Set slope to NaN for invalid data\n",
    "        else:\n",
    "            # Apply Theil-Sen regression\n",
    "            slope, _, _, _ = theilslopes(pixel_time_series, time)\n",
    "            slope_array[i, j] = slope  # Store the slope in the slope array\n",
    "\n",
    "# Step 7: Define the affine transform for the GeoTIFF\n",
    "transform = from_origin(np.min(lon), np.max(lat), np.abs(lon[1] - lon[0]), np.abs(lat[1] - lat[0]))\n",
    "\n",
    "# Step 8: Define the metadata for the GeoTIFF\n",
    "meta = {\n",
    "    'driver': 'GTiff',\n",
    "    'height': slope_array.shape[0],\n",
    "    'width': slope_array.shape[1],\n",
    "    'count': 1,  # Single band (slope)\n",
    "    'dtype': 'float32',\n",
    "    'crs': 'EPSG:4326',  # Assuming WGS84 (adjust if necessary)\n",
    "    'transform': transform\n",
    "}\n",
    "\n",
    "# Step 9: Save the slope result as a GeoTIFF\n",
    "output_tif = r'D:\\UCalgary_Lectures\\GEOG_683\\Data_workspace\\theil_sen_slope_1000mb_temp_yearly.tif'\n",
    "with rasterio.open(output_tif, 'w', **meta) as dst:\n",
    "    dst.write(slope_array, 1)  # Write the slope array to band 1\n",
    "\n",
    "print(f\"GeoTIFF saved as {output_tif}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quarterly average "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yearly averaged netCDF file saved as D:\\UCalgary_Lectures\\GEOG_683\\Data_workspace\\NAmerica_geopotential_1940_2023_2_quaterly.nc\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "\n",
    "# Step 1: Open the original ERA5 netCDF file\n",
    "nc_file = r'D:\\UCalgary_Lectures\\GEOG_683\\Data_workspace\\NAmerica_geopotential_1940_2023_2.nc'\n",
    "ds_2 = xr.open_dataset(nc_file)\n",
    "\n",
    "# Step 2: Resample the dataset to quarterly averages for each variable and pressure level\n",
    "# 'Q-DEC' groups data by quarters ending in December (standard quarterly grouping)\n",
    "ds_quarterly_avg = ds_2.resample(date='Q-DEC').mean()\n",
    "\n",
    "# Step 3: Save the quarterly averaged data to a new netCDF file\n",
    "output_nc_file = r'D:\\UCalgary_Lectures\\GEOG_683\\Data_workspace\\NAmerica_geopotential_1940_2023_2_quaterly.nc'\n",
    "ds_yearly_avg.to_netcdf(output_nc_file)\n",
    "\n",
    "print(f\"Yearly averaged netCDF file saved as {output_nc_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seasonal agerage (DJF, MAM, JJA, SON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seasonal averaged netCDF file with year associations saved as D:\\UCalgary_Lectures\\GEOG_683\\Data_workspace\\NAmerica_geopotential_1940_2023_2_seasonal.nc\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "\n",
    "# Step 1: Open the original ERA5 netCDF file\n",
    "nc_file = r'D:\\UCalgary_Lectures\\GEOG_683\\Data_workspace\\NAmerica_geopotential_1940_2023_2.nc'\n",
    "ds_2 = xr.open_dataset(nc_file)\n",
    "\n",
    "# Step 2: Use xarray's `.resample()` method to group by seasonal periods\n",
    "# We use the 'QS-DEC' argument to define quarterly resampling starting in December\n",
    "# This ensures DJF (Winter) starts in December and is associated with the correct year\n",
    "ds_seasonal_avg = ds_2.resample(date='QS-DEC').mean()\n",
    "\n",
    "# Step 3: Save the seasonal averaged data (with correct year associations) to a single netCDF file\n",
    "output_nc_file = r'D:\\UCalgary_Lectures\\GEOG_683\\Data_workspace\\NAmerica_geopotential_1940_2023_2_seasonal.nc'\n",
    "ds_seasonal_avg.to_netcdf(output_nc_file)\n",
    "\n",
    "print(f\"Seasonal averaged netCDF file with year associations saved as {output_nc_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeoTIFF saved as D:\\UCalgary_Lectures\\GEOG_683\\Data_workspace\\NAmerica_geopotential_1940_2023_2_DJF.tif\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "from scipy.stats import theilslopes\n",
    "import rasterio\n",
    "from rasterio.transform import from_origin\n",
    "\n",
    "# Step 1: Open the seasonal netCDF file\n",
    "nc_file = r'D:\\UCalgary_Lectures\\GEOG_683\\Data_workspace\\NAmerica_geopotential_1940_2023_2_seasonal.nc'\n",
    "ds_2 = xr.open_dataset(nc_file)\n",
    "\n",
    "# Step 2: Filter the dataset to only include DJF data\n",
    "# Assuming the resampled seasonal file includes 'DJF' as a season\n",
    "t_djf = ds_2.sel(date=ds_2['date.season'] == 'JJA')\n",
    "\n",
    "# Step 3: Extract the temperature data (or any other variable) for DJF\n",
    "# Here, we assume you're interested in 't' (temperature) at a specific pressure level\n",
    "t_djf_1000mb = t_djf['t'].sel(pressure_level=1000)\n",
    "\n",
    "# Step 4: Prepare the time values (in years) for DJF only\n",
    "# We use the 'date' variable to extract the year values corresponding to the DJF seasons\n",
    "years = t_djf_1000mb['date.year'].values\n",
    "\n",
    "# Step 5: Prepare the temperature data for DJF only\n",
    "temperature_data = t_djf_1000mb.values  # Extract the DJF temperature data\n",
    "\n",
    "# Step 6: Prepare latitude and longitude coordinates\n",
    "lat = t_djf_1000mb['latitude'].values\n",
    "lon = t_djf_1000mb['longitude'].values\n",
    "\n",
    "print(temperature_data.shape)\n",
    "\n",
    "# Step 7: Prepare an array to store the total temperature change over 84 years (DJF)\n",
    "total_temp_change_array = np.zeros((len(lat), len(lon)), dtype=np.float32)\n",
    "\n",
    "# Step 8: Perform Theil-Sen regression for each pixel (latitude, longitude) on DJF data\n",
    "years_period = 84  # Total number of years (1940-2024)\n",
    "\n",
    "for i in range(len(lat)):\n",
    "    for j in range(len(lon)):\n",
    "        # Extract the DJF temperature time series for the current pixel\n",
    "        pixel_time_series = temperature_data[:, i, j]\n",
    "\n",
    "        # Check if the pixel contains any NaN values (skip if invalid data)\n",
    "        if np.any(np.isnan(pixel_time_series)):\n",
    "            total_temp_change_array[i, j] = np.nan  # Set to NaN for invalid data\n",
    "        else:\n",
    "            # Apply Theil-Sen regression on DJF time series\n",
    "            slope, _, _, _ = theilslopes(pixel_time_series, years)\n",
    "            \n",
    "            # Multiply the slope by the total number of years to get total change over 84 years\n",
    "            total_temp_change_array[i, j] = slope * years_period  # Total temperature change for DJF\n",
    "\n",
    "# Step 9: Define the affine transform for the GeoTIFF\n",
    "transform = from_origin(np.min(lon), np.max(lat), np.abs(lon[1] - lon[0]), np.abs(lat[1] - lat[0]))\n",
    "\n",
    "# Step 10: Define the metadata for the GeoTIFF\n",
    "meta = {\n",
    "    'driver': 'GTiff',\n",
    "    'height': total_temp_change_array.shape[0],\n",
    "    'width': total_temp_change_array.shape[1],\n",
    "    'count': 1,  # Single band (total temperature change)\n",
    "    'dtype': 'float32',\n",
    "    'crs': 'EPSG:4326',  # Assuming WGS84 (adjust if necessary)\n",
    "    'transform': transform\n",
    "}\n",
    "\n",
    "# Step 11: Save the total temperature change result (for DJF only) as a GeoTIFF\n",
    "output_tif = r'D:\\UCalgary_Lectures\\GEOG_683\\Data_workspace\\NAmerica_geopotential_1940_2023_2_JJA.tif'\n",
    "with rasterio.open(output_tif, 'w', **meta) as dst:\n",
    "    dst.write(total_temp_change_array, 1)  # Write the total temperature change array to band 1\n",
    "\n",
    "print(f\"GeoTIFF saved as {output_tif}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:    (date: 788, latitude: 241, longitude: 481)\n",
      "Coordinates:\n",
      "    number     int64 ...\n",
      "  * date       (date) int64 19590101 19590201 19590301 ... 20240701 20240801\n",
      "  * latitude   (latitude) float64 85.0 84.75 84.5 84.25 ... 25.5 25.25 25.0\n",
      "  * longitude  (longitude) float64 -170.0 -169.8 -169.5 ... -50.5 -50.25 -50.0\n",
      "    expver     (date) object ...\n",
      "Data variables:\n",
      "    t2m        (date, latitude, longitude) float32 ...\n",
      "Attributes:\n",
      "    GRIB_centre:             ecmf\n",
      "    GRIB_centreDescription:  European Centre for Medium-Range Weather Forecasts\n",
      "    GRIB_subCentre:          0\n",
      "    Conventions:             CF-1.7\n",
      "    institution:             European Centre for Medium-Range Weather Forecasts\n",
      "    history:                 2024-09-13T17:14 GRIB to CDM+CF via cfgrib-0.9.1...\n"
     ]
    }
   ],
   "source": [
    "# ERA5 monthly averaged data on single levels from 1940 to present\n",
    "\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "\n",
    "ds_2 = xr.open_dataset(r\"D:\\UCalgary_Lectures\\GEOG_683\\Data_workspace\\Monthly_single_l\\data_0.nc\" , engine='netcdf4')\n",
    "\n",
    "# Inspect the data structure\n",
    "print(ds_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load the dataset and convert 'date' to datetime format\n",
    "ds_2['date'] = pd.to_datetime(ds_2['date'].values, format='%Y%m%d')\n",
    "\n",
    "# Step 2: Resample by year and calculate the yearly mean\n",
    "yearly_mean = ds_2.resample(date='Y').mean()\n",
    "\n",
    "# Step 3: Convert temperature to Fahrenheit\n",
    "yearly_mean['t2m'] = (yearly_mean['t2m'] - 273.15) * 9/5 + 32\n",
    "yearly_mean['t2m'].attrs['units'] = 'Fahrenheit'  # Update the units\n",
    "\n",
    "# Step 4: Save the new dataset to a NetCDF file\n",
    "yearly_mean.to_netcdf(r\"D:\\UCalgary_Lectures\\GEOG_683\\Data_workspace\\Monthly_single_l\\data_0_yearly_f.nc\")\n",
    "\n",
    "print(\"File saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:    (latitude: 241, longitude: 481, date: 66)\n",
      "Coordinates:\n",
      "    number     int64 ...\n",
      "  * latitude   (latitude) float64 85.0 84.75 84.5 84.25 ... 25.5 25.25 25.0\n",
      "  * longitude  (longitude) float64 -170.0 -169.8 -169.5 ... -50.5 -50.25 -50.0\n",
      "  * date       (date) datetime64[ns] 1959-12-31 1960-12-31 ... 2024-12-31\n",
      "Data variables:\n",
      "    t2m        (date, latitude, longitude) float32 ...\n",
      "Attributes:\n",
      "    GRIB_centre:             ecmf\n",
      "    GRIB_centreDescription:  European Centre for Medium-Range Weather Forecasts\n",
      "    GRIB_subCentre:          0\n",
      "    Conventions:             CF-1.7\n",
      "    institution:             European Centre for Medium-Range Weather Forecasts\n",
      "    history:                 2024-09-13T17:14 GRIB to CDM+CF via cfgrib-0.9.1...\n"
     ]
    }
   ],
   "source": [
    "ds_2 = xr.open_dataset(r\"D:\\UCalgary_Lectures\\GEOG_683\\Data_workspace\\Monthly_single_l\\data_0_yearly_f.nc\")\n",
    "\n",
    "print(ds_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeoTIFF saved as D:\\UCalgary_Lectures\\GEOG_683\\Data_workspace\\Monthly_single_l\\data_0_yearly_f_TheilS.tif\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import theilslopes\n",
    "import rasterio\n",
    "from rasterio.transform import from_origin\n",
    "\n",
    "# Step 1: Load the processed NetCDF file with yearly mean temperatures\n",
    "# ds_2 = xr.open_dataset('yearly_mean_temperature_fahrenheit.nc')\n",
    "\n",
    "# Step 2: Prepare data for regression (Extract time and temperatures)\n",
    "years = ds_2['date.year'].values  # Extract the years\n",
    "t2m_data = ds_2['t2m'].values     # Extract the temperature data\n",
    "\n",
    "# Get latitude and longitude from the dataset\n",
    "lat = ds_2['latitude'].values\n",
    "lon = ds_2['longitude'].values\n",
    "\n",
    "# Step 5: Prepare an array to store the Theil-Sen slopes\n",
    "slope_array = np.zeros((len(lat), len(lon)), dtype=np.float32)\n",
    "\n",
    "# Step 6: Perform Theil-Sen regression for each pixel (latitude, longitude)\n",
    "for i in range(len(lat)):\n",
    "    for j in range(len(lon)):\n",
    "        # Extract the temperature time series for the current pixel\n",
    "        pixel_time_series = t2m_data[:, i, j]\n",
    "        \n",
    "        # Check if the pixel contains any NaN values (skip if invalid data)\n",
    "        if np.any(np.isnan(pixel_time_series)):\n",
    "            slope_array[i, j] = np.nan  # Set slope to NaN for invalid data\n",
    "        else:\n",
    "            # Apply Theil-Sen regression\n",
    "            slope, _, _, _ = theilslopes(pixel_time_series, years)\n",
    "            slope_array[i, j] = slope  # Store the slope in the slope array\n",
    "\n",
    "# Step 7: Define the affine transform for the GeoTIFF\n",
    "transform = from_origin(np.min(lon), np.max(lat), np.abs(lon[1] - lon[0]), np.abs(lat[1] - lat[0]))\n",
    "\n",
    "# Step 8: Define the metadata for the GeoTIFF\n",
    "meta = {\n",
    "    'driver': 'GTiff',\n",
    "    'height': slope_array.shape[0],\n",
    "    'width': slope_array.shape[1],\n",
    "    'count': 1,  # Single band (slope)\n",
    "    'dtype': 'float32',\n",
    "    'crs': 'EPSG:4326',  # Assuming WGS84 (adjust if necessary)\n",
    "    'transform': transform\n",
    "}\n",
    "\n",
    "# Step 9: Save the slope result as a GeoTIFF\n",
    "output_tif = r'D:\\UCalgary_Lectures\\GEOG_683\\Data_workspace\\Monthly_single_l\\data_0_yearly_f_TheilS.tif'\n",
    "with rasterio.open(output_tif, 'w', **meta) as dst:\n",
    "    dst.write(slope_array, 1)  # Write the slope array to band 1\n",
    "\n",
    "print(f\"GeoTIFF saved as {output_tif}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
